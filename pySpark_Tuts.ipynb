{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7d9049",
   "metadata": {},
   "source": [
    "## Spark Tutorial By krish Naik\n",
    "https://www.youtube.com/watch?v=WyZmM6K7ubc&list=PLZoTAELRMXVNjiiawhzZ0afHcPvC8jpcg&index=1&ab_channel=KrishNaik\n",
    "\n",
    "https://github.com/kevinschaich/pyspark-cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4ac21",
   "metadata": {},
   "source": [
    "# Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80cf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51325284",
   "metadata": {},
   "source": [
    "#### Data Loding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebab9c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Starting Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373a665d-0385-43f8-af00-ffe6c5157e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f4e0c-5207-4879-9eac-7da5d50be5f5",
   "metadata": {},
   "source": [
    "#### Read Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8deb60-02b3-47fe-a28a-aded6a75a3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line No.</th>\n",
       "      <th>SHUTTLE NO.</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SDL3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDL2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDL2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDL3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDL1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Line No.  SHUTTLE NO.  Jan  Feb  Mar\n",
       "0     SDL3            3    1    0    0\n",
       "1     SDL2           26    0    0    0\n",
       "2     SDL2           27    0    0    1\n",
       "3     SDL3           28    0    0    1\n",
       "4     SDL1           29    1    0    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = pd.read_csv(\"shuttle_service_frq.csv\")\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74860ae-7646-4e9e-b8e8-8c122f765e6d",
   "metadata": {},
   "source": [
    "#### Read Data using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55621af5-fc52-4b4b-9ae0-ba6ab9e500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.csv(\"shuttle_service_frq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf1d7367-6988-4aff-bb72-2e7528e12a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef84eb9-9a44-4443-b784-2557bce5180d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='Line No.', _c1='SHUTTLE NO.', _c2='Jan', _c3='Feb', _c4='Mar')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc2a978-21d9-4c5b-8660-63c76eaa282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|     _c0|        _c1|_c2|_c3|_c4|\n",
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "|    SDL3|         28|  0|  0|  1|\n",
      "|    SDL1|         29|  1|  0|  0|\n",
      "|    SDL3|         30|  1|  0|  0|\n",
      "|    SDL2|         31|  0|  0|  0|\n",
      "|    SDL2|         32|  3|  0|  1|\n",
      "|    SDL3|         33|  0|  1|  0|\n",
      "|    SDL3|         34|  0|  0|  0|\n",
      "|    SDL4|         35|  1|  0|  1|\n",
      "|    SDL3|         36|  0|  1|  0|\n",
      "|    SDL1|         37|  0|  0|  0|\n",
      "|    SDL1|         38|  0|  0|  0|\n",
      "|    SDL3|         39|  0|  0|  0|\n",
      "|    SDL1|         40|  0|  0|  0|\n",
      "|    SDL3|         41|  0|  0|  0|\n",
      "|    SDL3|         42|  0|  0|  1|\n",
      "|    SDL4|         43|  0|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5845db5-1667-4f64-88d9-ad031035269b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: string, Jan: string, Feb: string, Mar: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sdf = spark.read.csv(\"shuttle_service_frq.csv\")\n",
    "sdf = spark.read.option('header', 'true').csv(\"shuttle_service_frq.csv\")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e5d53a9-501c-4cb2-a973-95eea15fba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "|    SDL3|         28|  0|  0|  1|\n",
      "|    SDL1|         29|  1|  0|  0|\n",
      "|    SDL3|         30|  1|  0|  0|\n",
      "|    SDL2|         31|  0|  0|  0|\n",
      "|    SDL2|         32|  3|  0|  1|\n",
      "|    SDL3|         33|  0|  1|  0|\n",
      "|    SDL3|         34|  0|  0|  0|\n",
      "|    SDL4|         35|  1|  0|  1|\n",
      "|    SDL3|         36|  0|  1|  0|\n",
      "|    SDL1|         37|  0|  0|  0|\n",
      "|    SDL1|         38|  0|  0|  0|\n",
      "|    SDL3|         39|  0|  0|  0|\n",
      "|    SDL1|         40|  0|  0|  0|\n",
      "|    SDL3|         41|  0|  0|  0|\n",
      "|    SDL3|         42|  0|  0|  1|\n",
      "|    SDL4|         43|  0|  0|  1|\n",
      "|    SDL3|         44|  0|  0|  0|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b01be7d-922f-45d5-a091-2fa4bcf98115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Line No.='SDL3', SHUTTLE NO.='3', Jan='1', Feb='0', Mar='0'),\n",
       " Row(Line No.='SDL2', SHUTTLE NO.='26', Jan='0', Feb='0', Mar='0'),\n",
       " Row(Line No.='SDL2', SHUTTLE NO.='27', Jan='0', Feb='0', Mar='1')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44613ed7-2509-49c2-98c4-7b82fe21832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type of sdf\n",
    "type(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc10336a-7a50-482e-89c7-2bbe7917acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Line No.: string (nullable = true)\n",
      " |-- SHUTTLE NO.: string (nullable = true)\n",
      " |-- Jan: string (nullable = true)\n",
      " |-- Feb: string (nullable = true)\n",
      " |-- Mar: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Schema \n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548acb4-4d4b-4d14-9479-fdae4bf8d2de",
   "metadata": {},
   "source": [
    "# Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f027b22-50ae-4c6d-a760-7b5bcf5565ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Dataframe\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a362616-835c-4c1f-a9a9-453b09eb91a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: string, Jan: string, Feb: string, Mar: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "sdf = spark.read.option('header', 'true').csv('shuttle_service_frq.csv') # take all columns as string\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961c1187-6937-470f-a090-e9f6e98b811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "|    SDL3|         28|  0|  0|  1|\n",
      "|    SDL1|         29|  1|  0|  0|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bace4a6d-9cf3-4b90-bb05-ff8831f2283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Line No.: string (nullable = true)\n",
      " |-- SHUTTLE NO.: string (nullable = true)\n",
      " |-- Jan: string (nullable = true)\n",
      " |-- Feb: string (nullable = true)\n",
      " |-- Mar: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0621486a-2831-4681-b669-2a574130bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "sdf = spark.read.option('header', 'true').csv('shuttle_service_frq.csv', inferSchema=True) \n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88703d73-6869-4dac-a585-5fc7d26084c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Line No.: string (nullable = true)\n",
      " |-- SHUTTLE NO.: integer (nullable = true)\n",
      " |-- Jan: integer (nullable = true)\n",
      " |-- Feb: integer (nullable = true)\n",
      " |-- Mar: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e67db-5adc-4bb0-92f1-8bbc721c1051",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a095c426-f62e-4330-a773-7b08348524dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv('shuttle_service_frq.csv', header=True, inferSchema=True)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee193f07-1410-4a59-8ade-cd6ef2541cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32fd540a-de11-4535-938d-fd30dd4ee8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Line No.: string (nullable = true)\n",
      " |-- SHUTTLE NO.: integer (nullable = true)\n",
      " |-- Jan: integer (nullable = true)\n",
      " |-- Feb: integer (nullable = true)\n",
      " |-- Mar: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3082173c-1682-483f-b603-9c71fa6d94d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf : \n",
      "DataFrame[Line No.: string]\n",
      "\n",
      "Type : \n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "\n",
      "+--------+\n",
      "|Line No.|\n",
      "+--------+\n",
      "|    SDL3|\n",
      "|    SDL2|\n",
      "|    SDL2|\n",
      "+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Line No column\n",
    "# column names containing spaces and special characters need to be properly escaped\n",
    "# or accessed using backticks\n",
    "print(\"sdf : \")\n",
    "print(sdf.select('`Line No.`'))\n",
    "print()\n",
    "print(\"Type : \")\n",
    "print(type(sdf.select('`Line No.`')))\n",
    "print()\n",
    "sdf.select('`Line No.`').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf105459-c835-436a-8469-3949c6119fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf : \n",
      "DataFrame[Jan: int]\n",
      "\n",
      "Type : \n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "\n",
      "+---+\n",
      "|Jan|\n",
      "+---+\n",
      "|  1|\n",
      "|  0|\n",
      "|  0|\n",
      "+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print \"Jan\" column\n",
    "# or accessed using backticks\n",
    "print(\"sdf : \")\n",
    "print(sdf.select('Jan'))\n",
    "print()\n",
    "print(\"Type : \")\n",
    "print(type(sdf.select('Jan')))\n",
    "print()\n",
    "sdf.select('Jan').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05a08ab-9068-4c63-aad9-6c4caa9f2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf : \n",
      "DataFrame[Line No.: string, Jan: int]\n",
      "\n",
      "Type : \n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "\n",
      "+--------+---+\n",
      "|Line No.|Jan|\n",
      "+--------+---+\n",
      "|    SDL3|  1|\n",
      "|    SDL2|  0|\n",
      "|    SDL2|  0|\n",
      "+--------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select multiple columns \n",
    "# or accessed using backticks\n",
    "print(\"sdf : \")\n",
    "print(sdf.select(['`Line No.`', 'Jan']))\n",
    "print()\n",
    "print(\"Type : \")\n",
    "print(type(sdf.select(['`Line No.`', 'Jan'])))\n",
    "print()\n",
    "sdf.select(['`Line No.`', 'Jan']).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c084e-0423-44b1-9986-f3fef279cd99",
   "metadata": {},
   "source": [
    "##### Column Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a185a98-3564-423b-b97f-b8eb4bab1ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Line No.', 'SHUTTLE NO.', 'Jan', 'Feb', 'Mar']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a7cb408-f3c4-4966-9879-75d26027aceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line_No\n",
      "SHUTTLE_NO\n",
      "Jan\n",
      "Feb\n",
      "Mar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Line_No: string, SHUTTLE_NO: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns to remove spaces and special characters\n",
    "for column in sdf.columns:\n",
    "    new_column_name = column.replace(' ', '_').replace('.', '')\n",
    "    print(new_column_name)\n",
    "    sdf = sdf.withColumnRenamed(column, new_column_name)\n",
    "    \n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb4b7fba-aee0-40d9-b169-d7d74b5056c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, Line_No: string, SHUTTLE_NO: string, Jan: string, Feb: string, Mar: string]\n",
      "\n",
      "+-------+-------+------------------+------------------+-------------------+-------------------+\n",
      "|summary|Line_No|        SHUTTLE_NO|               Jan|                Feb|                Mar|\n",
      "+-------+-------+------------------+------------------+-------------------+-------------------+\n",
      "|  count|    132|               134|               134|                134|                134|\n",
      "|   mean|   NULL|121.73134328358209|0.4253731343283582|0.14925373134328357|0.41044776119402987|\n",
      "| stddev|   NULL|136.46003376345536|0.8076408201115163| 0.3781128980976144| 0.6740371753782891|\n",
      "+-------+-------+------------------+------------------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe\n",
    "print(sdf.describe())\n",
    "print()\n",
    "sdf.describe().show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b876af7-c40e-418e-9732-c2b880b022f2",
   "metadata": {},
   "source": [
    "#### Adding Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0063338-6638-4b3b-8a0a-1a24bd0069cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+-----+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|April|\n",
      "+-------+----------+---+---+---+-----+\n",
      "|   SDL3|         3|  1|  0|  0|    2|\n",
      "|   SDL2|        26|  0|  0|  0|    2|\n",
      "|   SDL2|        27|  0|  0|  1|    3|\n",
      "|   SDL3|        28|  0|  0|  1|    3|\n",
      "|   SDL1|        29|  1|  0|  0|    2|\n",
      "+-------+----------+---+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add = sdf.withColumn('April', sdf['Mar']+2)\n",
    "add.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66d4a476-09dc-45a3-9cd9-df1457bc2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop = add.drop('April')\n",
    "drop.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dad5a-434b-4be2-aa8b-439491f6261c",
   "metadata": {},
   "source": [
    "# Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "742a93d1-338b-49fe-b1de-27a1eef7afd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "382a9f69-646c-4e94-bc26-a286eb74f47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv('shuttle_service_frq.csv', header=True, inferSchema=True)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a5f8087-b1a8-410a-b790-398d67916851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "183b4152-004a-4ed1-b6a4-aae63d8611c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line_No\n",
      "SHUTTLE_NO\n",
      "Jan\n",
      "Feb\n",
      "Mar\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to remove spaces and special characters\n",
    "for column in sdf.columns:\n",
    "    new_column_name = column.replace(' ', '_').replace('.', '')\n",
    "    print(new_column_name)\n",
    "    sdf = sdf.withColumnRenamed(column, new_column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73e02fd0-fcc7-4eda-b472-abe1e14973c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line_No\n",
      "SHUTTLE_NO\n",
      "Jan\n",
      "Feb\n",
      "Mar\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Line_No: string, SHUTTLE_NO: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in sdf.columns:\n",
    "    renamed_col = col.replace(' ', '_').replace('.', '')\n",
    "    print(renamed_col)\n",
    "    sdf = sdf.withColumnRenamed(col, renamed_col)\n",
    "\n",
    "print()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5a281-cdc6-4316-ba0c-a37bfa4f054f",
   "metadata": {},
   "source": [
    "#### Null Values Droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b65a79b-3e80-4759-b2d3-05979c0e5563",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "|   SDL3|        30|  1|  0|  0|\n",
      "|   SDL2|        31|  0|  0|  0|\n",
      "|   SDL2|        32|  3|  0|  1|\n",
      "|   SDL3|        33|  0|  1|  0|\n",
      "|   SDL3|        34|  0|  0|  0|\n",
      "|   SDL4|        35|  1|  0|  1|\n",
      "|   SDL3|        36|  0|  1|  0|\n",
      "|   SDL1|        37|  0|  0|  0|\n",
      "|   SDL1|        38|  0|  0|  0|\n",
      "|   SDL3|        39|  0|  0|  0|\n",
      "|   SDL1|        40|  0|  0|  0|\n",
      "|   SDL3|        41|  0|  0|  0|\n",
      "|   SDL3|        42|  0|  0|  1|\n",
      "|   SDL4|        43|  0|  0|  1|\n",
      "|   SDL3|        44|  0|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "|   SDL3|        30|  1|  0|  0|\n",
      "|   SDL2|        31|  0|  0|  0|\n",
      "|   SDL2|        32|  3|  0|  1|\n",
      "|   SDL3|        33|  0|  1|  0|\n",
      "|   SDL3|        34|  0|  0|  0|\n",
      "|   SDL4|        35|  1|  0|  1|\n",
      "|   SDL3|        36|  0|  1|  0|\n",
      "|   SDL1|        37|  0|  0|  0|\n",
      "|   SDL1|        38|  0|  0|  0|\n",
      "|   SDL3|        39|  0|  0|  0|\n",
      "|   SDL1|        40|  0|  0|  0|\n",
      "|   SDL3|        41|  0|  0|  0|\n",
      "|   SDL3|        42|  0|  0|  1|\n",
      "|   SDL4|        43|  0|  0|  1|\n",
      "|   SDL3|        44|  0|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "|   SDL3|        30|  1|  0|  0|\n",
      "|   SDL2|        31|  0|  0|  0|\n",
      "|   SDL2|        32|  3|  0|  1|\n",
      "|   SDL3|        33|  0|  1|  0|\n",
      "|   SDL3|        34|  0|  0|  0|\n",
      "|   SDL4|        35|  1|  0|  1|\n",
      "|   SDL3|        36|  0|  1|  0|\n",
      "|   SDL1|        37|  0|  0|  0|\n",
      "|   SDL1|        38|  0|  0|  0|\n",
      "|   SDL3|        39|  0|  0|  0|\n",
      "|   SDL1|        40|  0|  0|  0|\n",
      "|   SDL3|        41|  0|  0|  0|\n",
      "|   SDL3|        42|  0|  0|  1|\n",
      "|   SDL4|        43|  0|  0|  1|\n",
      "|   SDL3|        44|  0|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "|   SDL3|        30|  1|  0|  0|\n",
      "|   SDL2|        31|  0|  0|  0|\n",
      "|   SDL2|        32|  3|  0|  1|\n",
      "|   SDL3|        33|  0|  1|  0|\n",
      "|   SDL3|        34|  0|  0|  0|\n",
      "|   SDL4|        35|  1|  0|  1|\n",
      "|   SDL3|        36|  0|  1|  0|\n",
      "|   SDL1|        37|  0|  0|  0|\n",
      "|   SDL1|        38|  0|  0|  0|\n",
      "|   SDL3|        39|  0|  0|  0|\n",
      "|   SDL1|        40|  0|  0|  0|\n",
      "|   SDL3|        41|  0|  0|  0|\n",
      "|   SDL3|        42|  0|  0|  1|\n",
      "|   SDL4|        43|  0|  0|  1|\n",
      "|   SDL3|        44|  0|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop Null rows\n",
    "sdf.na.drop(how='any').show()   # Drop if any NUll is there\n",
    "sdf.na.drop(how='all').show()   # Drop if all are NUll there\n",
    "sdf.na.drop(how='any', thresh=2).show()   # Drop if alteaset 2 null.\n",
    "sdf.na.drop(how='any',subset='Jan').show()   # Drop if null in 'Jan' Column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32626f6-1302-41a2-aa25-b7a0af71f49e",
   "metadata": {},
   "source": [
    "#### Null Values filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "648bfd84-4dbc-4c4b-8507-50a44db499df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.na.fill(\"Missing Values\").show(5)   # Fillna using \"Missing Valuues in all df\n",
    "sdf.na.fill(\"Missing Values\", ['Jan', 'Feb']).show(5)   # Fillna using \"Missing Valuues in ['Jan', 'Feb'] columns\n",
    "sdf.na.fill(\"Missing Values\", ['Jan', 'Feb']).show(5)   # Fillna using mean9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f98a81de-870e-4230-a16a-7fe022d82f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Initialize the Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols  = ['Jan', 'Feb', 'Mar'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['Jan', 'Feb', 'Mar']]\n",
    ").setStrategy('mean')\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "sdf_imputed = imputer.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5762c6a3-884d-4ab4-aed0-af1302ead81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+-----------+-----------+-----------+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|Jan_imputed|Feb_imputed|Mar_imputed|\n",
      "+-------+----------+---+---+---+-----------+-----------+-----------+\n",
      "|   SDL3|         3|  1|  0|  0|          1|          0|          0|\n",
      "|   SDL2|        26|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL2|        27|  0|  0|  1|          0|          0|          1|\n",
      "|   SDL3|        28|  0|  0|  1|          0|          0|          1|\n",
      "|   SDL1|        29|  1|  0|  0|          1|          0|          0|\n",
      "|   SDL3|        30|  1|  0|  0|          1|          0|          0|\n",
      "|   SDL2|        31|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL2|        32|  3|  0|  1|          3|          0|          1|\n",
      "|   SDL3|        33|  0|  1|  0|          0|          1|          0|\n",
      "|   SDL3|        34|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL4|        35|  1|  0|  1|          1|          0|          1|\n",
      "|   SDL3|        36|  0|  1|  0|          0|          1|          0|\n",
      "|   SDL1|        37|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL1|        38|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL3|        39|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL1|        40|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL3|        41|  0|  0|  0|          0|          0|          0|\n",
      "|   SDL3|        42|  0|  0|  1|          0|          0|          1|\n",
      "|   SDL4|        43|  0|  0|  1|          0|          0|          1|\n",
      "|   SDL3|        44|  0|  0|  0|          0|          0|          0|\n",
      "+-------+----------+---+---+---+-----------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the result\n",
    "sdf_imputed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ae2ee-9b22-467d-a83d-e3eaeb701c63",
   "metadata": {},
   "source": [
    "# Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06419111-8556-45be-86e3-93e39f3841bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8428e67-2cb2-4b54-9e61-599a753de172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv('shuttle_service_frq.csv', header=True, inferSchema=True)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dd74c3f-45a2-4c9b-84bd-a042dbdeac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb59956-cd20-4d7c-bd9f-1eef775a1622",
   "metadata": {},
   "source": [
    "#### Filter Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2a9c879-f30a-42b9-a821-472b7217d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL2|         32|  3|  0|  1|\n",
      "|    SDL1|         62|  3|  0|  2|\n",
      "|    SDL2|         84|  3|  0|  0|\n",
      "|    SDL2|         95|  2|  0|  0|\n",
      "|    SDL2|        108|  2|  0|  0|\n",
      "|    SDL1|        110|  2|  0|  2|\n",
      "|    SDL1|        115|  2|  1|  2|\n",
      "|    SDL4|        123|  3|  0|  1|\n",
      "|    SDL2|        124|  2|  0|  0|\n",
      "|    SDL4|        125|  4|  0|  0|\n",
      "|    SDL1|        144|  3|  0|  3|\n",
      "|    SDL2|        151|  2|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Jan >= 2\n",
    "# sdf.filter('Jan>=2').show()\n",
    "sdf.filter('Jan>=2').show()\n",
    "# sdf.filter('Jan>=2').select(['jan', 'Feb']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4c0f0-8efa-4c4c-b84f-f3d866041e52",
   "metadata": {},
   "source": [
    "###### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb5d4ed5-114d-499e-b465-598c025c1c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL2|         32|  3|  0|  1|\n",
      "|    SDL1|         62|  3|  0|  2|\n",
      "|    SDL2|         84|  3|  0|  0|\n",
      "|    SDL2|         95|  2|  0|  0|\n",
      "|    SDL2|        108|  2|  0|  0|\n",
      "|    SDL1|        110|  2|  0|  2|\n",
      "|    SDL1|        115|  2|  1|  2|\n",
      "|    SDL4|        123|  3|  0|  1|\n",
      "|    SDL2|        124|  2|  0|  0|\n",
      "|    SDL4|        125|  4|  0|  0|\n",
      "|    SDL1|        144|  3|  0|  3|\n",
      "|    SDL2|        151|  2|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.filter(sdf['Jan']>=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1262acdf-32e7-4fb3-92c4-477b3cc4ecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL1|        115|  2|  1|  2|\n",
      "+--------+-----------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.filter((sdf['Jan']>=2) & (sdf['Feb']>=1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c46066c-1106-45e3-9261-d72d63c33a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "|    SDL3|         28|  0|  0|  1|\n",
      "|    SDL2|         31|  0|  0|  0|\n",
      "|    SDL3|         34|  0|  0|  0|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use of NOT\n",
    "sdf.filter(~(sdf['Jan']>=1) & ~(sdf['Feb']>=1)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb65b3d-ff3e-45db-b53c-ab86b93ed398",
   "metadata": {},
   "source": [
    "# Day 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ffefbe3-bfa3-414a-b72a-8166fa559d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark  = SparkSession.builder.appName(\"Practoice\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40e1eb29-bb6a-420e-953a-723010f36a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv('shuttle_service_frq.csv', header=True, inferSchema=True)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d92f0605-83cb-4538-ad6c-6d47994f1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "|    SDL3|         28|  0|  0|  1|\n",
      "|    SDL1|         29|  1|  0|  0|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581da99-381c-4038-9146-463d62565c1c",
   "metadata": {},
   "source": [
    "#### Groupby/Aggregation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "399c4292-e254-4cbe-99f1-880aa493fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sdf.columns:\n",
    "    new_col = col.replace(\".\", \"\").replace(\" \", \"_\")\n",
    "    sdf = sdf.withColumnRenamed(col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39616fcb-f6a6-492a-b614-3bd32b038c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "870ecc88-bb84-41cb-96dc-faf15c60b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+--------+--------+--------+\n",
      "|Jan|sum(SHUTTLE_NO)|sum(Jan)|sum(Feb)|sum(Mar)|\n",
      "+---+---------------+--------+--------+--------+\n",
      "|  1|           2714|      26|       6|       9|\n",
      "|  3|            445|      15|       0|       7|\n",
      "|  4|            125|       4|       0|       0|\n",
      "|  2|            703|      12|       1|       5|\n",
      "|  0|          12325|       0|      13|      34|\n",
      "+---+---------------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.groupby('Jan').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8490aca4-3e29-4cef-bb1d-1cbd38e92fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(Jan)|\n",
      "+--------+\n",
      "|      57|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.agg({'Jan':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9c45ae5-51fc-4ce0-87f8-5645834e79d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+--------+--------+--------+\n",
      "|Jan|min(SHUTTLE_NO)|min(Jan)|min(Feb)|min(Mar)|\n",
      "+---+---------------+--------+--------+--------+\n",
      "|  1|              3|       1|       0|       0|\n",
      "|  3|             32|       3|       0|       0|\n",
      "|  4|            125|       4|       0|       0|\n",
      "|  2|             95|       2|       0|       0|\n",
      "|  0|             26|       0|       0|       0|\n",
      "+---+---------------+--------+--------+--------+\n",
      "\n",
      "+---+---------------+--------+--------+--------+\n",
      "|Jan|max(SHUTTLE_NO)|max(Jan)|max(Feb)|max(Mar)|\n",
      "+---+---------------+--------+--------+--------+\n",
      "|  1|            451|       1|       1|       2|\n",
      "|  3|            144|       3|       0|       3|\n",
      "|  4|            125|       4|       0|       0|\n",
      "|  2|            151|       2|       1|       2|\n",
      "|  0|            787|       0|       2|       3|\n",
      "+---+---------------+--------+--------+--------+\n",
      "\n",
      "+---+------------------+--------+-------------------+-------------------+\n",
      "|Jan|   avg(SHUTTLE_NO)|avg(Jan)|           avg(Feb)|           avg(Mar)|\n",
      "+---+------------------+--------+-------------------+-------------------+\n",
      "|  1|104.38461538461539|     1.0|0.23076923076923078|0.34615384615384615|\n",
      "|  3|              89.0|     3.0|                0.0|                1.4|\n",
      "|  4|             125.0|     4.0|                0.0|                0.0|\n",
      "|  2|117.16666666666667|     2.0|0.16666666666666666| 0.8333333333333334|\n",
      "|  0|128.38541666666666|     0.0|0.13541666666666666| 0.3541666666666667|\n",
      "+---+------------------+--------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.groupby('Jan').min().show()\n",
    "sdf.groupby('Jan').max().show()\n",
    "sdf.groupby('Jan').avg().show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9170d7c-180a-4d77-a3a4-a27cff5b7d79",
   "metadata": {},
   "source": [
    "# Day 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c533d88c-568b-4f5a-812a-3ed06b14309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Muqesh-QHUG4S1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29c403eedc0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sp = SparkSession.builder.appName(\"mLib\").getOrCreate()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c1c2ef9-3c65-4e68-8401-b1daf03d54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Line No.: string, SHUTTLE NO.: int, Jan: int, Feb: int, Mar: int]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = sp.read.csv('shuttle_service_frq.csv', header=True, inferSchema=True)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f31deee-6730-412e-a2d8-3ada36c23d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---+---+---+\n",
      "|Line No.|SHUTTLE NO.|Jan|Feb|Mar|\n",
      "+--------+-----------+---+---+---+\n",
      "|    SDL3|          3|  1|  0|  0|\n",
      "|    SDL2|         26|  0|  0|  0|\n",
      "|    SDL2|         27|  0|  0|  1|\n",
      "+--------+-----------+---+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ac102-704f-4547-9770-a37eeff7bb3d",
   "metadata": {},
   "source": [
    "##### MLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f0d6451-3f33-4117-add0-dc029e26aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sdf.columns:\n",
    "    new_Col = col.replace(' ', '_').replace(\".\", '')\n",
    "    sdf = sdf.withColumnRenamed(col, new_Col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f53e2e5a-9536-4d71-bad3-ec3dd8601d8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---+---+---+\n",
      "|Line_No|SHUTTLE_NO|Jan|Feb|Mar|\n",
      "+-------+----------+---+---+---+\n",
      "|   SDL3|         3|  1|  0|  0|\n",
      "|   SDL2|        26|  0|  0|  0|\n",
      "|   SDL2|        27|  0|  0|  1|\n",
      "|   SDL3|        28|  0|  0|  1|\n",
      "|   SDL1|        29|  1|  0|  0|\n",
      "+-------+----------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8d88e-0d01-4fd1-95f9-abd292ce6739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835825f7-bc49-4c64-9856-5bde20d40d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
